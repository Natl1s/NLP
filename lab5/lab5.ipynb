{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7cASdGnwN6w0",
    "outputId": "a301fd79-b19d-4496-d7f7-345b31ed93a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy3 in /home/dream_on/miniconda3/lib/python3.13/site-packages (2.0.6)\n",
      "Requirement already satisfied: dawg2-python>=0.8.0 in /home/dream_on/miniconda3/lib/python3.13/site-packages (from pymorphy3) (0.9.0)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in /home/dream_on/miniconda3/lib/python3.13/site-packages (from pymorphy3) (2.4.417150.4580142)\n",
      "Requirement already satisfied: setuptools>=68.2.2 in /home/dream_on/miniconda3/lib/python3.13/site-packages (from pymorphy3) (80.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 13:06:09.151425: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-26 13:06:09.504103: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-26 13:06:10.965299: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "[nltk_data] Downloading package punkt to /home/dream_on/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/dream_on/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install pymorphy3\n",
    "\n",
    "import tensorflow as tf\n",
    "import pymorphy3\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, GlobalMaxPooling1D, TimeDistributed, Flatten, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-OqnOq2IN_3E"
   },
   "outputs": [],
   "source": [
    "morph = pymorphy3.MorphAnalyzer()\n",
    "max_len = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GqRlCsiToJhX"
   },
   "outputs": [],
   "source": [
    "int_to_str = ['NOUN',\n",
    "            'ADJF',\n",
    "            'ADJS',\n",
    "            'VERB',\n",
    "            'INFN',\n",
    "            'NUMR',\n",
    "            'PRTF',\n",
    "            'PRTS',\n",
    "            'GRND',\n",
    "            'PREP',\n",
    "            'PRCL',\n",
    "            'CONJ',\n",
    "            'NPRO',\n",
    "            'ADVB',\n",
    "            'COMP',\n",
    "            'NONE',\n",
    "            'PRED',\n",
    "            'INTJ']\n",
    "str_to_int = {}\n",
    "for i, j in enumerate(int_to_str):\n",
    "  str_to_int[j] = i\n",
    "\n",
    "character_count = 35 # количество символов - 33 буквы, ' ' и '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8-5hGTRBUCWx"
   },
   "outputs": [],
   "source": [
    "def process_data(sentence):\n",
    "  sentence += ' '\n",
    "  global max_len\n",
    "  word = \"\"\n",
    "  x = []\n",
    "  y = []\n",
    "  cnt = 0\n",
    "  for ch in sentence:\n",
    "    ch = ch.lower()\n",
    "    if ord(ch) >= ord('а') and ord(ch) <= ord('я'):\n",
    "      word += ch\n",
    "      ohe = [0 for _ in range(character_count)]\n",
    "      ohe[ord(ch) - ord('а')] = 1\n",
    "      x.append(np.array(ohe))\n",
    "      y.append('NONE')\n",
    "    elif ch == '-':\n",
    "      word += ch\n",
    "      ohe = [0 for _ in range(character_count)]\n",
    "      ohe[character_count - 2] = 1\n",
    "      x.append(np.array(ohe))\n",
    "      y.append('NONE')\n",
    "    elif ch == ' ': # дошли до конца слова\n",
    "      if word == '':\n",
    "        continue\n",
    "      ohe = [0 for _ in range(character_count)]\n",
    "      ohe[character_count - 1] = 1\n",
    "      x.append(np.array(ohe))\n",
    "      y.append(morph.parse(word)[0].tag.POS) # делаем морфлогический разбор, достаем тег части речи\n",
    "      word = \"\"\n",
    "  y = ['NONE' if tag is None else tag for tag in y]\n",
    "  y = [str_to_int[tag] for tag in y]\n",
    "  max_len = max(max_len, len(x))\n",
    "  # print(y)\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91smkXMhOK5N",
    "outputId": "096f96b8-f842-476f-934c-b8b8dff290f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasterAndMargarita.txt is done reading\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "books = [\"MasterAndMargarita.txt\"]\n",
    "\n",
    "for book in books:\n",
    "    with open(\"./files/books_before/\" + book,\"r\") as f:\n",
    "        content = f.read()\n",
    "    raw_sentences = re.split(r'[.!?]', content) # разбиваем на предложения\n",
    "    for sentence in raw_sentences:\n",
    "      x, y = process_data(sentence)\n",
    "      X.append(x)\n",
    "      Y.append(y)\n",
    "    print(f\"{book} is done reading\")\n",
    "    \n",
    "for i in range(len(X)):\n",
    "  while len(X[i]) < max_len:\n",
    "    X[i].append(np.array([0 for _ in range(character_count)])) # добиваем ohe предложения до максимальной длины слова нулями (т.е. никакой из нужных символов)\n",
    "    Y[i].append(str_to_int['NONE']) # И соответственно тег части речи отсутствует\n",
    "  X[i] = np.array(X[i])\n",
    "  Y[i] = np.array(Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "567"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cazlTSp15W9M"
   },
   "outputs": [],
   "source": [
    "num_classes = len(str_to_int)\n",
    "\n",
    "Y_arr = np.array(Y, dtype='int32')      # (N, max_len)\n",
    "y_flat = Y_arr.flatten()              # (N * max_len,)\n",
    "classes = np.arange(num_classes)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_flat\n",
    ")\n",
    "\n",
    "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "pad_idx = str_to_int['NONE']\n",
    "class_weight_dict[pad_idx] = 0.1\n",
    "sample_weight = np.zeros_like(Y_arr, dtype='float32')  # (N, max_len)\n",
    "\n",
    "for cls_idx, w in class_weight_dict.items():\n",
    "    sample_weight[Y_arr == cls_idx] = w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hgkwDHZtQ4sP",
    "outputId": "766433a4-543f-42b7-bdf0-27bfe7f5d0a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 11:16:04.332546: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/home/dream_on/miniconda3/lib/python3.13/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 498ms/step - accuracy: 0.8672 - loss: 2.4248 - val_accuracy: 0.8562 - val_loss: 2.3636\n",
      "Epoch 2/5\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 484ms/step - accuracy: 0.8825 - loss: 1.5552 - val_accuracy: 0.8751 - val_loss: 1.5166\n",
      "Epoch 3/5\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 481ms/step - accuracy: 0.9158 - loss: 1.1146 - val_accuracy: 0.9245 - val_loss: 1.2189\n",
      "Epoch 4/5\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 483ms/step - accuracy: 0.9558 - loss: 0.9188 - val_accuracy: 0.9600 - val_loss: 1.0671\n",
      "Epoch 5/5\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 482ms/step - accuracy: 0.9743 - loss: 0.7812 - val_accuracy: 0.9784 - val_loss: 0.9318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f710c5eacf0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(Bidirectional(LSTM(units=64, input_shape=(None, max_len, character_count), return_sequences=True)))\n",
    "lstm_model.add(TimeDistributed(Dense(len(str_to_int), activation='softmax')))\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lstm_model.fit(np.array(X), np.array(Y), epochs=5, batch_size=32, validation_split=0.2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nQnD9vOTyPZk"
   },
   "outputs": [],
   "source": [
    "lstm_model.save('model_lstm.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eULbQjH-AG2l"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 12:52:47.477055: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "lstm_model = load_model('model_lstm.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZseL33aUbMf",
    "outputId": "083f49aa-d0ce-45b0-d544-52244ad628c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 35)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
      "Он - NPRO\n",
      "сбросил - VERB\n",
      "с - PREP\n",
      "себя - NPRO\n",
      "шинель - VERB\n",
      "и - CONJ\n",
      "так - CONJ\n",
      "весело - VERB\n",
      "таким - ADJF\n",
      "молоденьким - ADJF\n",
      "мальчиком - ADJF\n",
      "посмотрел - VERB\n",
      "на - PREP\n",
      "отца - NOUN\n"
     ]
    }
   ],
   "source": [
    "s = 'Он сбросил с себя шинель и так весело, таким молоденьким мальчиком посмотрел на отца '\n",
    "s = re.sub(r'[^\\w\\s]', '', s)\n",
    "x, y = process_data(s)\n",
    "while len(x) < max_len:\n",
    "  x.append(np.zeros(character_count))\n",
    "  y.append(str_to_int['NONE'])\n",
    "print(np.array(x).shape)\n",
    "ans = lstm_model.predict(np.array([x]))\n",
    "for i in range(len(s)):\n",
    "  tmp = int_to_str[np.argmax(ans[0][i])]\n",
    "  print(s[i], end = '')\n",
    "  if s[i] == ' ':\n",
    "    print('-', tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e8sjPcDsChvK"
   },
   "outputs": [],
   "source": [
    "max_len_word = 26\n",
    "\n",
    "def process_data_words(sentence):\n",
    "  sentence += ' '\n",
    "  global max_len \n",
    "  word = \"\"\n",
    "  x = []\n",
    "  y = []\n",
    "  cnt = 0\n",
    "  word_tmp = []\n",
    "  for ch in sentence:\n",
    "    ch = ch.lower()\n",
    "    if ord(ch) >= ord('а') and ord(ch) <= ord('я'):\n",
    "      word += ch\n",
    "      ohe = [0 for _ in range(character_count)]\n",
    "      ohe[ord(ch) - ord('а')] = 1\n",
    "      word_tmp.append(np.array(ohe))\n",
    "    elif ch == '-':\n",
    "      word += ch\n",
    "      ohe = [0 for _ in range(character_count)]\n",
    "      ohe[character_count - 2] = 1\n",
    "      word_tmp.append(np.array(ohe))\n",
    "    elif ch == ' ': # дошли до конца слова\n",
    "      if word == '':\n",
    "        continue\n",
    "      ohe = [0 for _ in range(character_count)]\n",
    "      ohe[character_count - 1] = 1\n",
    "      while len(word_tmp) < max_len_word:\n",
    "        word_tmp.append(np.array(ohe))\n",
    "      x.append(word_tmp)\n",
    "      y.append(morph.parse(word)[0].tag.POS) # делаем морфлогический разбор, достаем тег части речи\n",
    "      word = \"\"\n",
    "      word_tmp = []\n",
    "  y = ['NONE' if tag is None else tag for tag in y]\n",
    "  y = [str_to_int[tag] for tag in y]\n",
    "  max_len = max(max_len, len(x))\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ze2O0xOuCm2n",
    "outputId": "315b7a03-a8c7-4b19-842a-c12c4ee732ce",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasterAndMargarita.txt is done reading\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "X = []\n",
    "Y = []\n",
    "books = [\"MasterAndMargarita.txt\"]\n",
    "\n",
    "for book in books:\n",
    "    with open(\"./files/books_before/\" + book,\"r\") as f:\n",
    "        content = f.read()\n",
    "    raw_sentences = re.split(r'[.!?]', content) # разбиваем на предложения\n",
    "    for sentence in raw_sentences:\n",
    "      x, y = process_data_words(sentence)\n",
    "      X.append(x)\n",
    "      Y.append(y)\n",
    "    print(f\"{book} is done reading\")\n",
    "\n",
    "for i in range(len(X)):\n",
    "  while len(X[i]) < max_len:\n",
    "    X[i].append([np.array([0 for _ in range(character_count)]) for _ in range(max_len_word)])\n",
    "    Y[i].append(str_to_int['NONE'])\n",
    "  X[i] = np.array(X[i])\n",
    "  Y[i] = np.array(Y[i])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qNUI2NEVy1Ez"
   },
   "outputs": [],
   "source": [
    "num_classes = len(str_to_int)\n",
    "\n",
    "Y_arr = np.array(Y, dtype='int32')\n",
    "y_flat = Y_arr.reshape(-1)\n",
    "classes = np.arange(num_classes)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_flat\n",
    ")\n",
    "\n",
    "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "pad_idx = str_to_int['NONE']\n",
    "class_weight_dict[pad_idx] = 0.1\n",
    "sample_weight = np.zeros_like(Y_arr, dtype='float32')\n",
    "\n",
    "for cls_idx, w in class_weight_dict.items():\n",
    "    sample_weight[Y_arr == cls_idx] = w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "SFBpFS9LDlNd",
    "outputId": "7e2f721c-07e9-4d3d-f2fc-4a82ecc84116"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 13:08:39.561015: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,784</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,170</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m35\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m6,784\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │         \u001b[38;5;34m1,170\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,914</span> (159.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,914\u001b[0m (159.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,914</span> (159.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,914\u001b[0m (159.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "inputs = Input(shape=(max_len, max_len_word, character_count))\n",
    "\n",
    "# 1. Свёртка по символам каждого слова\n",
    "char_conv = layers.TimeDistributed(\n",
    "    layers.Conv1D(filters=64,\n",
    "                  kernel_size=3,\n",
    "                  padding='same',\n",
    "                  activation='relu')\n",
    ")(inputs)\n",
    "\n",
    "# 2. Пулинг по символам → вектор на слово\n",
    "word_vectors = layers.TimeDistributed(layers.GlobalMaxPooling1D())(char_conv)\n",
    "\n",
    "# 3. Свёртка по словам\n",
    "context = layers.Conv1D(filters=128, kernel_size=3, padding='same', activation='relu')(word_vectors)\n",
    "\n",
    "# 4. Dense для каждого слова\n",
    "dense_out = layers.TimeDistributed(\n",
    "    layers.Dense(64, activation='relu')\n",
    ")(context)\n",
    "\n",
    "# 5. Выход: POS-теги для каждого слова\n",
    "outputs = layers.TimeDistributed(\n",
    "    layers.Dense(len(str_to_int), activation='softmax')\n",
    ")(dense_out)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRsH3PSfNkZh",
    "outputId": "2447fa29-1eb0-47ff-9733-1d035c5e2c99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 141ms/step - accuracy: 0.8953 - loss: 1.9036 - val_accuracy: 0.9380 - val_loss: 1.2857\n",
      "Epoch 2/5\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 132ms/step - accuracy: 0.9513 - loss: 0.8445 - val_accuracy: 0.9513 - val_loss: 0.8968\n",
      "Epoch 3/5\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 134ms/step - accuracy: 0.9648 - loss: 0.5786 - val_accuracy: 0.9627 - val_loss: 0.6427\n",
      "Epoch 4/5\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 139ms/step - accuracy: 0.9721 - loss: 0.4396 - val_accuracy: 0.9688 - val_loss: 0.5355\n",
      "Epoch 5/5\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 136ms/step - accuracy: 0.9762 - loss: 0.3510 - val_accuracy: 0.9729 - val_loss: 0.4741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbaaa75f8c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X), np.array(Y), epochs=5, batch_size=32, validation_split=0.2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "04eX_-jMxn6L"
   },
   "outputs": [],
   "source": [
    "model.save('model_cnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rvRoNuvjxjSC"
   },
   "outputs": [],
   "source": [
    "cnn_model = load_model('model_cnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zXW9Uf7zArd4",
    "outputId": "0be56b5b-82cd-4bac-b352-7ae0f471270b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Он - NPRO\n",
      "сбросил - VERB\n",
      "с - PREP\n",
      "себя - NPRO\n",
      "шинель - NOUN\n",
      "и - CONJ\n",
      "так - CONJ\n",
      "весело - ADJS\n",
      "таким - ADJF\n",
      "молоденьким - ADJF\n",
      "мальчиком - NOUN\n",
      "посмотрел - VERB\n",
      "на - PREP\n",
      "отца - NOUN\n"
     ]
    }
   ],
   "source": [
    "s = 'Он сбросил с себя шинель и так весело, таким молоденьким мальчиком посмотрел на отца '\n",
    "s = re.sub(r'[^\\w\\s]', '', s)\n",
    "x, y = process_data_words(s)\n",
    "while len(x) < max_len:\n",
    "    x.append([np.array([0 for _ in range(character_count)]) for _ in range(max_len_word)])\n",
    "    y.append(str_to_int['NONE'])\n",
    "ans = cnn_model.predict(np.array([x]))\n",
    "\n",
    "j=0\n",
    "for i in range(len(s)):\n",
    "  tmp = int_to_str[np.argmax(ans[0][j])]\n",
    "  print(s[i], end = '')\n",
    "  if s[i] == ' ':\n",
    "    j+=1\n",
    "    print('-', tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
